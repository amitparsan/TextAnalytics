from nltk.tokenize import word_tokenize, send_tokenize, stopwords
data = "All work and no play makes jack dull boy. All work and no play makes jack a dull boy."
words = print(word_tokenize(data))
phrases = print(send_tokenize(data))
